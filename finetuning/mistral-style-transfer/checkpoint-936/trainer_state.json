{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.992,
  "eval_steps": 500,
  "global_step": 936,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.032,
      "grad_norm": NaN,
      "learning_rate": 0.00019871794871794874,
      "loss": 1.6661,
      "step": 10
    },
    {
      "epoch": 0.064,
      "grad_norm": 2.885056972503662,
      "learning_rate": 0.00019679487179487178,
      "loss": 1.2611,
      "step": 20
    },
    {
      "epoch": 0.096,
      "grad_norm": 2.328962564468384,
      "learning_rate": 0.00019465811965811965,
      "loss": 1.1107,
      "step": 30
    },
    {
      "epoch": 0.128,
      "grad_norm": 5.345825672149658,
      "learning_rate": 0.00019252136752136753,
      "loss": 1.1327,
      "step": 40
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.8885610103607178,
      "learning_rate": 0.00019038461538461538,
      "loss": 1.0969,
      "step": 50
    },
    {
      "epoch": 0.192,
      "grad_norm": 1.6461762189865112,
      "learning_rate": 0.00018824786324786325,
      "loss": 1.1019,
      "step": 60
    },
    {
      "epoch": 0.224,
      "grad_norm": 1.779942512512207,
      "learning_rate": 0.00018611111111111112,
      "loss": 1.0681,
      "step": 70
    },
    {
      "epoch": 0.256,
      "grad_norm": 1.726569414138794,
      "learning_rate": 0.00018397435897435897,
      "loss": 1.133,
      "step": 80
    },
    {
      "epoch": 0.288,
      "grad_norm": 1.4438437223434448,
      "learning_rate": 0.00018183760683760684,
      "loss": 1.0588,
      "step": 90
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.7070133686065674,
      "learning_rate": 0.00017970085470085472,
      "loss": 1.07,
      "step": 100
    },
    {
      "epoch": 0.352,
      "grad_norm": 1.4939202070236206,
      "learning_rate": 0.00017756410256410257,
      "loss": 1.096,
      "step": 110
    },
    {
      "epoch": 0.384,
      "grad_norm": 1.5400532484054565,
      "learning_rate": 0.00017542735042735044,
      "loss": 1.0534,
      "step": 120
    },
    {
      "epoch": 0.416,
      "grad_norm": 1.3493200540542603,
      "learning_rate": 0.00017329059829059831,
      "loss": 1.077,
      "step": 130
    },
    {
      "epoch": 0.448,
      "grad_norm": 1.3710832595825195,
      "learning_rate": 0.00017115384615384616,
      "loss": 1.0645,
      "step": 140
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.4365620613098145,
      "learning_rate": 0.00016901709401709403,
      "loss": 1.0465,
      "step": 150
    },
    {
      "epoch": 0.512,
      "grad_norm": 1.548335313796997,
      "learning_rate": 0.00016688034188034188,
      "loss": 1.0396,
      "step": 160
    },
    {
      "epoch": 0.544,
      "grad_norm": 1.491760015487671,
      "learning_rate": 0.00016474358974358976,
      "loss": 1.0465,
      "step": 170
    },
    {
      "epoch": 0.576,
      "grad_norm": 1.3735920190811157,
      "learning_rate": 0.0001626068376068376,
      "loss": 1.0633,
      "step": 180
    },
    {
      "epoch": 0.608,
      "grad_norm": 1.4891670942306519,
      "learning_rate": 0.00016047008547008548,
      "loss": 1.0499,
      "step": 190
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.695955514907837,
      "learning_rate": 0.00015833333333333332,
      "loss": 1.122,
      "step": 200
    },
    {
      "epoch": 0.672,
      "grad_norm": 1.6194710731506348,
      "learning_rate": 0.0001561965811965812,
      "loss": 1.0613,
      "step": 210
    },
    {
      "epoch": 0.704,
      "grad_norm": 1.2345771789550781,
      "learning_rate": 0.00015405982905982907,
      "loss": 1.111,
      "step": 220
    },
    {
      "epoch": 0.736,
      "grad_norm": 1.2724390029907227,
      "learning_rate": 0.00015192307692307692,
      "loss": 1.0607,
      "step": 230
    },
    {
      "epoch": 0.768,
      "grad_norm": 1.2255992889404297,
      "learning_rate": 0.0001497863247863248,
      "loss": 1.0636,
      "step": 240
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.351892113685608,
      "learning_rate": 0.00014764957264957267,
      "loss": 1.0495,
      "step": 250
    },
    {
      "epoch": 0.832,
      "grad_norm": 1.3506836891174316,
      "learning_rate": 0.00014551282051282051,
      "loss": 1.0525,
      "step": 260
    },
    {
      "epoch": 0.864,
      "grad_norm": 1.2349165678024292,
      "learning_rate": 0.0001433760683760684,
      "loss": 1.0811,
      "step": 270
    },
    {
      "epoch": 0.896,
      "grad_norm": 1.238787293434143,
      "learning_rate": 0.00014123931623931626,
      "loss": 1.0722,
      "step": 280
    },
    {
      "epoch": 0.928,
      "grad_norm": 1.5467015504837036,
      "learning_rate": 0.0001391025641025641,
      "loss": 1.0838,
      "step": 290
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.1787643432617188,
      "learning_rate": 0.00013696581196581198,
      "loss": 1.0511,
      "step": 300
    },
    {
      "epoch": 0.992,
      "grad_norm": 1.485912561416626,
      "learning_rate": 0.00013482905982905986,
      "loss": 1.0564,
      "step": 310
    },
    {
      "epoch": 1.0224,
      "grad_norm": 1.3123252391815186,
      "learning_rate": 0.0001326923076923077,
      "loss": 0.9803,
      "step": 320
    },
    {
      "epoch": 1.0544,
      "grad_norm": 1.551838755607605,
      "learning_rate": 0.00013055555555555555,
      "loss": 0.9764,
      "step": 330
    },
    {
      "epoch": 1.0864,
      "grad_norm": 1.276220440864563,
      "learning_rate": 0.00012841880341880343,
      "loss": 0.9781,
      "step": 340
    },
    {
      "epoch": 1.1184,
      "grad_norm": 1.5792807340621948,
      "learning_rate": 0.00012628205128205127,
      "loss": 0.9608,
      "step": 350
    },
    {
      "epoch": 1.1504,
      "grad_norm": 1.4074254035949707,
      "learning_rate": 0.00012414529914529915,
      "loss": 0.9512,
      "step": 360
    },
    {
      "epoch": 1.1824,
      "grad_norm": 1.3946192264556885,
      "learning_rate": 0.00012200854700854702,
      "loss": 1.0019,
      "step": 370
    },
    {
      "epoch": 1.2144,
      "grad_norm": 1.2768614292144775,
      "learning_rate": 0.00011987179487179487,
      "loss": 0.9582,
      "step": 380
    },
    {
      "epoch": 1.2464,
      "grad_norm": 1.2679110765457153,
      "learning_rate": 0.00011773504273504274,
      "loss": 0.956,
      "step": 390
    },
    {
      "epoch": 1.2784,
      "grad_norm": 1.56464684009552,
      "learning_rate": 0.00011559829059829059,
      "loss": 0.9873,
      "step": 400
    },
    {
      "epoch": 1.3104,
      "grad_norm": 1.5033355951309204,
      "learning_rate": 0.00011346153846153846,
      "loss": 0.9516,
      "step": 410
    },
    {
      "epoch": 1.3424,
      "grad_norm": 1.4036686420440674,
      "learning_rate": 0.00011132478632478634,
      "loss": 0.9949,
      "step": 420
    },
    {
      "epoch": 1.3744,
      "grad_norm": 1.4030942916870117,
      "learning_rate": 0.00010918803418803418,
      "loss": 0.9701,
      "step": 430
    },
    {
      "epoch": 1.4064,
      "grad_norm": 1.3940980434417725,
      "learning_rate": 0.00010705128205128206,
      "loss": 0.935,
      "step": 440
    },
    {
      "epoch": 1.4384000000000001,
      "grad_norm": 1.4435160160064697,
      "learning_rate": 0.00010491452991452992,
      "loss": 0.9457,
      "step": 450
    },
    {
      "epoch": 1.4704,
      "grad_norm": 1.4944487810134888,
      "learning_rate": 0.00010277777777777778,
      "loss": 0.9634,
      "step": 460
    },
    {
      "epoch": 1.5024,
      "grad_norm": 1.4912734031677246,
      "learning_rate": 0.00010064102564102564,
      "loss": 0.9432,
      "step": 470
    },
    {
      "epoch": 1.5344,
      "grad_norm": 1.3599989414215088,
      "learning_rate": 9.850427350427351e-05,
      "loss": 0.9752,
      "step": 480
    },
    {
      "epoch": 1.5664,
      "grad_norm": 1.3926198482513428,
      "learning_rate": 9.636752136752137e-05,
      "loss": 0.9645,
      "step": 490
    },
    {
      "epoch": 1.5984,
      "grad_norm": 1.5614298582077026,
      "learning_rate": 9.423076923076924e-05,
      "loss": 0.9611,
      "step": 500
    },
    {
      "epoch": 1.6303999999999998,
      "grad_norm": 1.288510799407959,
      "learning_rate": 9.20940170940171e-05,
      "loss": 0.9494,
      "step": 510
    },
    {
      "epoch": 1.6623999999999999,
      "grad_norm": 1.4024507999420166,
      "learning_rate": 8.995726495726497e-05,
      "loss": 0.9823,
      "step": 520
    },
    {
      "epoch": 1.6944,
      "grad_norm": 1.227978229522705,
      "learning_rate": 8.782051282051283e-05,
      "loss": 0.9585,
      "step": 530
    },
    {
      "epoch": 1.7264,
      "grad_norm": 1.445549726486206,
      "learning_rate": 8.568376068376068e-05,
      "loss": 0.9898,
      "step": 540
    },
    {
      "epoch": 1.7584,
      "grad_norm": 1.400728702545166,
      "learning_rate": 8.354700854700855e-05,
      "loss": 0.9621,
      "step": 550
    },
    {
      "epoch": 1.7904,
      "grad_norm": 1.490560531616211,
      "learning_rate": 8.141025641025641e-05,
      "loss": 0.9962,
      "step": 560
    },
    {
      "epoch": 1.8224,
      "grad_norm": 1.4935587644577026,
      "learning_rate": 7.927350427350427e-05,
      "loss": 0.9807,
      "step": 570
    },
    {
      "epoch": 1.8544,
      "grad_norm": 1.7054938077926636,
      "learning_rate": 7.713675213675215e-05,
      "loss": 0.9828,
      "step": 580
    },
    {
      "epoch": 1.8864,
      "grad_norm": 1.423153281211853,
      "learning_rate": 7.500000000000001e-05,
      "loss": 0.9537,
      "step": 590
    },
    {
      "epoch": 1.9184,
      "grad_norm": 1.4080883264541626,
      "learning_rate": 7.286324786324787e-05,
      "loss": 0.9682,
      "step": 600
    },
    {
      "epoch": 1.9504000000000001,
      "grad_norm": 1.4874897003173828,
      "learning_rate": 7.072649572649573e-05,
      "loss": 0.9915,
      "step": 610
    },
    {
      "epoch": 1.9824000000000002,
      "grad_norm": 1.367517352104187,
      "learning_rate": 6.858974358974359e-05,
      "loss": 0.961,
      "step": 620
    },
    {
      "epoch": 2.0128,
      "grad_norm": 1.2416433095932007,
      "learning_rate": 6.645299145299145e-05,
      "loss": 0.8964,
      "step": 630
    },
    {
      "epoch": 2.0448,
      "grad_norm": 1.4158375263214111,
      "learning_rate": 6.431623931623932e-05,
      "loss": 0.9013,
      "step": 640
    },
    {
      "epoch": 2.0768,
      "grad_norm": 1.5683351755142212,
      "learning_rate": 6.217948717948718e-05,
      "loss": 0.8998,
      "step": 650
    },
    {
      "epoch": 2.1088,
      "grad_norm": 1.4567192792892456,
      "learning_rate": 6.0042735042735044e-05,
      "loss": 0.9255,
      "step": 660
    },
    {
      "epoch": 2.1408,
      "grad_norm": 1.4475767612457275,
      "learning_rate": 5.790598290598291e-05,
      "loss": 0.8542,
      "step": 670
    },
    {
      "epoch": 2.1728,
      "grad_norm": 1.5192469358444214,
      "learning_rate": 5.576923076923077e-05,
      "loss": 0.8706,
      "step": 680
    },
    {
      "epoch": 2.2048,
      "grad_norm": 1.8585999011993408,
      "learning_rate": 5.363247863247863e-05,
      "loss": 0.8713,
      "step": 690
    },
    {
      "epoch": 2.2368,
      "grad_norm": 1.453865885734558,
      "learning_rate": 5.149572649572649e-05,
      "loss": 0.8568,
      "step": 700
    },
    {
      "epoch": 2.2688,
      "grad_norm": 1.675110101699829,
      "learning_rate": 4.935897435897436e-05,
      "loss": 0.8686,
      "step": 710
    },
    {
      "epoch": 2.3008,
      "grad_norm": 1.4918644428253174,
      "learning_rate": 4.722222222222222e-05,
      "loss": 0.8957,
      "step": 720
    },
    {
      "epoch": 2.3327999999999998,
      "grad_norm": 1.6474583148956299,
      "learning_rate": 4.508547008547009e-05,
      "loss": 0.8962,
      "step": 730
    },
    {
      "epoch": 2.3648,
      "grad_norm": 1.6969505548477173,
      "learning_rate": 4.294871794871795e-05,
      "loss": 0.8683,
      "step": 740
    },
    {
      "epoch": 2.3968,
      "grad_norm": 1.554111123085022,
      "learning_rate": 4.0811965811965816e-05,
      "loss": 0.8693,
      "step": 750
    },
    {
      "epoch": 2.4288,
      "grad_norm": 1.7911224365234375,
      "learning_rate": 3.867521367521368e-05,
      "loss": 0.8637,
      "step": 760
    },
    {
      "epoch": 2.4608,
      "grad_norm": 1.5416814088821411,
      "learning_rate": 3.653846153846154e-05,
      "loss": 0.8528,
      "step": 770
    },
    {
      "epoch": 2.4928,
      "grad_norm": 1.732563853263855,
      "learning_rate": 3.4401709401709405e-05,
      "loss": 0.9229,
      "step": 780
    },
    {
      "epoch": 2.5248,
      "grad_norm": 1.595125675201416,
      "learning_rate": 3.2264957264957265e-05,
      "loss": 0.8771,
      "step": 790
    },
    {
      "epoch": 2.5568,
      "grad_norm": 1.7997994422912598,
      "learning_rate": 3.012820512820513e-05,
      "loss": 0.9015,
      "step": 800
    },
    {
      "epoch": 2.5888,
      "grad_norm": 1.6163009405136108,
      "learning_rate": 2.7991452991452993e-05,
      "loss": 0.9087,
      "step": 810
    },
    {
      "epoch": 2.6208,
      "grad_norm": 1.8284510374069214,
      "learning_rate": 2.5854700854700857e-05,
      "loss": 0.8588,
      "step": 820
    },
    {
      "epoch": 2.6528,
      "grad_norm": 1.5016058683395386,
      "learning_rate": 2.3717948717948718e-05,
      "loss": 0.8516,
      "step": 830
    },
    {
      "epoch": 2.6848,
      "grad_norm": 1.7073006629943848,
      "learning_rate": 2.1581196581196585e-05,
      "loss": 0.9134,
      "step": 840
    },
    {
      "epoch": 2.7168,
      "grad_norm": 1.9040181636810303,
      "learning_rate": 1.9444444444444445e-05,
      "loss": 0.8649,
      "step": 850
    },
    {
      "epoch": 2.7488,
      "grad_norm": 1.6880261898040771,
      "learning_rate": 1.730769230769231e-05,
      "loss": 0.9248,
      "step": 860
    },
    {
      "epoch": 2.7808,
      "grad_norm": 1.6864081621170044,
      "learning_rate": 1.517094017094017e-05,
      "loss": 0.8619,
      "step": 870
    },
    {
      "epoch": 2.8128,
      "grad_norm": 1.6835230588912964,
      "learning_rate": 1.3034188034188035e-05,
      "loss": 0.8759,
      "step": 880
    },
    {
      "epoch": 2.8448,
      "grad_norm": 1.7031875848770142,
      "learning_rate": 1.0897435897435898e-05,
      "loss": 0.8896,
      "step": 890
    },
    {
      "epoch": 2.8768000000000002,
      "grad_norm": 1.5053601264953613,
      "learning_rate": 8.76068376068376e-06,
      "loss": 0.8406,
      "step": 900
    },
    {
      "epoch": 2.9088000000000003,
      "grad_norm": 1.6207890510559082,
      "learning_rate": 6.623931623931625e-06,
      "loss": 0.864,
      "step": 910
    },
    {
      "epoch": 2.9408,
      "grad_norm": 1.757117748260498,
      "learning_rate": 4.487179487179488e-06,
      "loss": 0.8907,
      "step": 920
    },
    {
      "epoch": 2.9728,
      "grad_norm": 1.6257507801055908,
      "learning_rate": 2.3504273504273504e-06,
      "loss": 0.8605,
      "step": 930
    }
  ],
  "logging_steps": 10,
  "max_steps": 936,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.2694207529353216e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
